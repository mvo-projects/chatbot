# initialize the mode ("train" or "eval")
[init]
mode = eval
use_cuda = no

[data]
min_length = 2
max_length = 13
delay = 5
trim_min_count = 10
use_qacorpus = yes
create_qapairs = no
qacorpuspaths = ./OpenSubtitles2018/xml/fr
qapairspath = qa_totalpairs.txt
corpuspaths = ./OpenSubtitles2018/xml/fr/2016,./OpenSubtitles2018/xml/fr/2017

# attention_method : "dot", "general" or "concat"
[model]
attn_model = dot
hidden_size = 1024
n_layers = 2
dropout = 0.3
learning_rate = 0.0001
decoder_learning_ratio = 5.0
optimizer = Adam
criterion = CrossEntropyLoss

[load]
load_training = yes
load_encoderpath = ./encoderQA
load_decoderpath = ./decoderQA

[training]
batch_size = 128
clip = 50.0
teacher_forcing_ratio = 0.5
iteration = 0
n_iterations = 100000
save_every = 10000
print_every = 100
evaluate_every = 1000
save_encoderpath = encoder_QA_nocaps_accents
save_decoderpath = decoder_QA_nocaps_accents

[eval]
max_length = 13
temperature_module_name = temp
temperature_function_name = inverse_fun
n_words_vocab = 10
