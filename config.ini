# initialize the mode ("train" or "eval")
[init]
mode = eval

[data]
min_length = 2
max_length = 13
trim_min_count = 5
use_qacorpus = no
create_qapairs = no
qacorpuspaths = ./OpenSubtitles2018/xml/fr
qapairspath = qa_totalpairs.txt
corpuspaths = ./OpenSubtitles2018/xml/fr/2016,./OpenSubtitles2018/xml/fr/2017

# attention_method : "dot", "general" or "concat"
# 
[model]
attn_model = general
hidden_size = 1024
n_layers = 3
dropout = 0.3
batch_size = 128
optimizer = Adam
criterion = CrossEntropyLoss

[load]
load_training = yes
load_encoderpath = ./encoder_corpus2016_2017
load_decoderpath = ./decoder_corpus2016_2017

[training]
use_cuda = no
clip = 50.0
teacher_forcing_ratio = 0.5
learning_rate = 0.0001
decoder_learning_ratio = 5.0
iteration = 0
n_iterations = 100000
save_every = 10000
print_every = 100
evaluate_every = 1000
save_encoderpath = encoder_QA_nocaps_accents
save_decoderpath = decoder_QA_nocaps_accents

[eval]
max_length = 13
use_cuda = no
temperature_module_name = temp
temperature_function_name = mytempfunc
n_words_vocab = 10
